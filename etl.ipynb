{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "\n",
    "\n",
    "def reader(url):\n",
    "  url = url\n",
    "  s = requests.get(url).content\n",
    "  t = io.StringIO(s.decode('utf-8'))\n",
    "  ds = pd.read_csv(t)\n",
    "  return(ds)\n",
    "\n",
    "data_2019 = reader(\"https://www-static.bouldercolorado.gov/docs/opendata/CouncilEmails_PlainText2019.csv\")\n",
    "data_2020 = reader(\"https://www-static.bouldercolorado.gov/docs/opendata/CouncilEmails_PlainText2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is the second iteration created. I did the first iteration of the LDA model in R however, I was coming up against memory constraints using my personal computer. I switched over to a python environment so I could use the free Google Colab tool and have access to cloud compute.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "The data cleaning we do is pretty simple.\n",
    "\n",
    "1. We remove all no reply type emails. These are typically automated emails that aren't relevant to this study.\n",
    "1. We remove all stop words that do not provide value in a probablistic model such as LDA\n",
    "1. We stem and lemmatize the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentFrom</th>\n",
       "      <th>SentTo</th>\n",
       "      <th>SentCC</th>\n",
       "      <th>ReceivedDate</th>\n",
       "      <th>EmailSubject</th>\n",
       "      <th>PlainTextBody</th>\n",
       "      <th>MessageIdentifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Petition For Boulder Homeless Services</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31 22:44:46.0000000 +00:00</td>\n",
       "      <td>Petition For Homeless Services, Signature Numb...</td>\n",
       "      <td>Dear Boulder City Council members, We are writ...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Petition For Boulder Homeless Services</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31 20:20:04.0000000 +00:00</td>\n",
       "      <td>Petition For Homeless Services, Signature Numb...</td>\n",
       "      <td>Dear Boulder City Council members, We are writ...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petition For Boulder Homeless Services</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31 19:28:02.0000000 +00:00</td>\n",
       "      <td>Petition For Homeless Services, Signature Numb...</td>\n",
       "      <td>Dear Boulder City Council members, We are writ...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petition For Boulder Homeless Services</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31 15:37:14.0000000 +00:00</td>\n",
       "      <td>Petition For Homeless Services, Signature Numb...</td>\n",
       "      <td>Dear Boulder City Council members, We are writ...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petition For Boulder Homeless Services</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31 15:26:31.0000000 +00:00</td>\n",
       "      <td>Petition For Homeless Services, Signature Numb...</td>\n",
       "      <td>Dear Boulder City Council members, We are writ...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7630</th>\n",
       "      <td>David Figueroa</td>\n",
       "      <td>Ana Vangelena, Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01 13:36:34.0000000 +00:00</td>\n",
       "      <td>Jon Benet Ramsey 2019</td>\n",
       "      <td>“My vision concerning Jon Benet Ramsey By Davi...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7631</th>\n",
       "      <td>Meagan Arango</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01 11:51:35.0000000 +00:00</td>\n",
       "      <td>Severe Weather Shelter - Support ASAP</td>\n",
       "      <td>Greetings Council, and Happy New Year to you. ...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>Max Weller</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01 11:45:27.0000000 +00:00</td>\n",
       "      <td>STAY SOBER and stay alive outdoors!</td>\n",
       "      <td>Dear Council members, Same message I've been p...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7633</th>\n",
       "      <td>Kenneth Flowe</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01 08:54:04.0000000 +00:00</td>\n",
       "      <td>Updated: 2019 Martin Luther King Day Talent Sh...</td>\n",
       "      <td>This is a note to invite you to a very excitin...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>No Reply</td>\n",
       "      <td>Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01 07:12:36.0000000 +00:00</td>\n",
       "      <td>Messages on hold for [6bb18bf32d5a8f2798e95f9c...</td>\n",
       "      <td>The following messages, addressed to Council, ...</td>\n",
       "      <td>AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7635 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    SentFrom                  SentTo SentCC  \\\n",
       "0     Petition For Boulder Homeless Services                 Council    NaN   \n",
       "1     Petition For Boulder Homeless Services                 Council    NaN   \n",
       "2     Petition For Boulder Homeless Services                 Council    NaN   \n",
       "3     Petition For Boulder Homeless Services                 Council    NaN   \n",
       "4     Petition For Boulder Homeless Services                 Council    NaN   \n",
       "...                                      ...                     ...    ...   \n",
       "7630                          David Figueroa  Ana Vangelena, Council    NaN   \n",
       "7631                           Meagan Arango                 Council    NaN   \n",
       "7632                              Max Weller                 Council    NaN   \n",
       "7633                           Kenneth Flowe                 Council    NaN   \n",
       "7634                                No Reply                 Council    NaN   \n",
       "\n",
       "                            ReceivedDate  \\\n",
       "0     2019-12-31 22:44:46.0000000 +00:00   \n",
       "1     2019-12-31 20:20:04.0000000 +00:00   \n",
       "2     2019-12-31 19:28:02.0000000 +00:00   \n",
       "3     2019-12-31 15:37:14.0000000 +00:00   \n",
       "4     2019-12-31 15:26:31.0000000 +00:00   \n",
       "...                                  ...   \n",
       "7630  2019-01-01 13:36:34.0000000 +00:00   \n",
       "7631  2019-01-01 11:51:35.0000000 +00:00   \n",
       "7632  2019-01-01 11:45:27.0000000 +00:00   \n",
       "7633  2019-01-01 08:54:04.0000000 +00:00   \n",
       "7634  2019-01-01 07:12:36.0000000 +00:00   \n",
       "\n",
       "                                           EmailSubject  \\\n",
       "0     Petition For Homeless Services, Signature Numb...   \n",
       "1     Petition For Homeless Services, Signature Numb...   \n",
       "2     Petition For Homeless Services, Signature Numb...   \n",
       "3     Petition For Homeless Services, Signature Numb...   \n",
       "4     Petition For Homeless Services, Signature Numb...   \n",
       "...                                                 ...   \n",
       "7630                              Jon Benet Ramsey 2019   \n",
       "7631              Severe Weather Shelter - Support ASAP   \n",
       "7632                STAY SOBER and stay alive outdoors!   \n",
       "7633  Updated: 2019 Martin Luther King Day Talent Sh...   \n",
       "7634  Messages on hold for [6bb18bf32d5a8f2798e95f9c...   \n",
       "\n",
       "                                          PlainTextBody  \\\n",
       "0     Dear Boulder City Council members, We are writ...   \n",
       "1     Dear Boulder City Council members, We are writ...   \n",
       "2     Dear Boulder City Council members, We are writ...   \n",
       "3     Dear Boulder City Council members, We are writ...   \n",
       "4     Dear Boulder City Council members, We are writ...   \n",
       "...                                                 ...   \n",
       "7630  “My vision concerning Jon Benet Ramsey By Davi...   \n",
       "7631  Greetings Council, and Happy New Year to you. ...   \n",
       "7632  Dear Council members, Same message I've been p...   \n",
       "7633  This is a note to invite you to a very excitin...   \n",
       "7634  The following messages, addressed to Council, ...   \n",
       "\n",
       "                                      MessageIdentifier  \n",
       "0     AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "1     AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "2     AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "3     AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "4     AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "...                                                 ...  \n",
       "7630  AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "7631  AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "7632  AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "7633  AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "7634  AAMkADQ2ZmVlYWI4LWI1MmEtNDc1NC05ZjhkLTI5YTA3ZD...  \n",
       "\n",
       "[7635 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "def cleaner(raw_data):\n",
    "    data = raw_data[raw_data.SentFrom != \"No Reply\"]\n",
    "    data = data.dropna(subset=['PlainTextBody'])\n",
    "    return(data)\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result    \n",
    "    \n",
    "    \n",
    "#.apply(lambda x: [item for item in x if item not in stop])   \n",
    "#data = cleaner( \n",
    "#    pd.concat([data_2019, data_2020]))\n",
    "\n",
    "data = cleaner(pd.concat([data_2019, data_2020]))\n",
    "#display(data)\n",
    "processed_docs = data['PlainTextBody'].map(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [dear, boulder, citi, council, member, write, ...\n",
       "1    [dear, boulder, citi, council, member, write, ...\n",
       "2    [dear, boulder, citi, council, member, write, ...\n",
       "3    [dear, boulder, citi, council, member, write, ...\n",
       "4    [dear, boulder, citi, council, member, write, ...\n",
       "5    [dear, boulder, citi, council, member, write, ...\n",
       "6    [dear, boulder, citi, council, member, write, ...\n",
       "7    [dear, boulder, citi, council, member, write, ...\n",
       "8    [dear, boulder, citi, council, member, write, ...\n",
       "9    [hello, council, member, write, today, respons...\n",
       "Name: PlainTextBody, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 absorb\n",
      "1 access\n",
      "2 addit\n",
      "3 address\n",
      "4 adjud\n",
      "5 affili\n",
      "6 appoint\n",
      "7 appropri\n",
      "8 area\n",
      "9 aris\n",
      "10 base\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "        \n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 38 (\"fund\") appears 4 time.\n",
      "Word 39 (\"help\") appears 2 time.\n",
      "Word 48 (\"million\") appears 1 time.\n",
      "Word 54 (\"open\") appears 4 time.\n",
      "Word 69 (\"repres\") appears 1 time.\n",
      "Word 91 (\"write\") appears 1 time.\n",
      "Word 92 (\"year\") appears 1 time.\n",
      "Word 132 (\"general\") appears 1 time.\n",
      "Word 137 (\"hope\") appears 1 time.\n",
      "Word 142 (\"increas\") appears 1 time.\n",
      "Word 147 (\"major\") appears 1 time.\n",
      "Word 153 (\"opportun\") appears 1 time.\n",
      "Word 176 (\"today\") appears 1 time.\n",
      "Word 184 (\"sarah\") appears 2 time.\n",
      "Word 222 (\"kind\") appears 1 time.\n",
      "Word 229 (\"recent\") appears 2 time.\n",
      "Word 286 (\"consid\") appears 1 time.\n",
      "Word 356 (\"includ\") appears 1 time.\n",
      "Word 394 (\"park\") appears 5 time.\n",
      "Word 414 (\"quick\") appears 1 time.\n",
      "Word 422 (\"requir\") appears 1 time.\n",
      "Word 452 (\"town\") appears 1 time.\n",
      "Word 457 (\"uniqu\") appears 1 time.\n",
      "Word 460 (\"user\") appears 1 time.\n",
      "Word 468 (\"work\") appears 1 time.\n",
      "Word 497 (\"rais\") appears 3 time.\n",
      "Word 498 (\"rang\") appears 1 time.\n",
      "Word 529 (\"annual\") appears 1 time.\n",
      "Word 596 (\"councilwoman\") appears 1 time.\n",
      "Word 678 (\"potenti\") appears 1 time.\n",
      "Word 706 (\"student\") appears 3 time.\n",
      "Word 754 (\"benefit\") appears 1 time.\n",
      "Word 818 (\"tax\") appears 2 time.\n",
      "Word 848 (\"direct\") appears 4 time.\n",
      "Word 852 (\"explor\") appears 1 time.\n",
      "Word 875 (\"mountain\") appears 2 time.\n",
      "Word 888 (\"space\") appears 4 time.\n",
      "Word 893 (\"support\") appears 2 time.\n",
      "Word 943 (\"flow\") appears 2 time.\n",
      "Word 992 (\"univers\") appears 1 time.\n",
      "Word 1048 (\"local\") appears 1 time.\n",
      "Word 1118 (\"develop\") appears 1 time.\n",
      "Word 1204 (\"option\") appears 1 time.\n",
      "Word 1282 (\"charg\") appears 2 time.\n",
      "Word 1312 (\"dedic\") appears 2 time.\n",
      "Word 1337 (\"empow\") appears 1 time.\n",
      "Word 1342 (\"entir\") appears 1 time.\n",
      "Word 1516 (\"sourc\") appears 1 time.\n",
      "Word 1530 (\"suggest\") appears 1 time.\n",
      "Word 1533 (\"sustain\") appears 2 time.\n",
      "Word 1701 (\"encourag\") appears 2 time.\n",
      "Word 1731 (\"measur\") appears 1 time.\n",
      "Word 1734 (\"rental\") appears 1 time.\n",
      "Word 1791 (\"revenu\") appears 2 time.\n",
      "Word 1832 (\"fee\") appears 2 time.\n",
      "Word 1850 (\"maintain\") appears 4 time.\n",
      "Word 1873 (\"usag\") appears 1 time.\n",
      "Word 1887 (\"heavi\") appears 1 time.\n",
      "Word 2039 (\"asset\") appears 2 time.\n",
      "Word 2048 (\"calcul\") appears 1 time.\n",
      "Word 2267 (\"silver\") appears 2 time.\n",
      "Word 2430 (\"visitor\") appears 1 time.\n",
      "Word 2432 (\"weekend\") appears 1 time.\n",
      "Word 2458 (\"reli\") appears 1 time.\n",
      "Word 2460 (\"tool\") appears 1 time.\n",
      "Word 2554 (\"draw\") appears 1 time.\n",
      "Word 2732 (\"portion\") appears 1 time.\n",
      "Word 2996 (\"airbnb\") appears 1 time.\n",
      "Word 3380 (\"transfer\") appears 1 time.\n",
      "Word 3503 (\"hotel\") appears 1 time.\n",
      "Word 3751 (\"osmp\") appears 7 time.\n",
      "Word 4219 (\"alik\") appears 1 time.\n",
      "Word 4420 (\"expir\") appears 1 time.\n",
      "Word 4521 (\"morzel\") appears 1 time.\n",
      "Word 5277 (\"reinstat\") appears 1 time.\n",
      "Word 5470 (\"fadf\") appears 1 time.\n",
      "Word 5471 (\"fefa\") appears 1 time.\n",
      "Word 5730 (\"chautauqua\") appears 1 time.\n",
      "Word 5772 (\"greatest\") appears 1 time.\n",
      "Word 6199 (\"tourism\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "\n",
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFull\u001b[0m                                      Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                         \u001b[0mjob_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m                         \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFull\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-80e2941bc13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     workers=3)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;31m# in case the input job queue is full, keep clearing the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                         \u001b[0;31m# result queue, to make sure we don't deadlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                         \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \"\"\"\n\u001b[1;32m    267\u001b[0m             \u001b[0mmerged_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_topics = 15\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(\n",
    "    bow_corpus, \n",
    "    num_topics=num_topics, \n",
    "    id2word=dictionary, \n",
    "    passes=2, \n",
    "    workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.013*\"open\" + 0.012*\"space\" + 0.012*\"flood\" + 0.009*\"plan\" + 0.009*\"protect\" + 0.009*\"year\" + 0.008*\"south\" + 0.008*\"communiti\" + 0.007*\"muni\" + 0.007*\"cost\"\n",
      "Topic: 1 \n",
      "Words: 0.007*\"plan\" + 0.006*\"public\" + 0.006*\"communiti\" + 0.006*\"build\" + 0.006*\"meet\" + 0.006*\"area\" + 0.006*\"need\" + 0.005*\"work\" + 0.005*\"project\" + 0.005*\"time\"\n",
      "Topic: 2 \n",
      "Words: 0.046*\"polic\" + 0.024*\"communiti\" + 0.022*\"depart\" + 0.013*\"hous\" + 0.011*\"resid\" + 0.010*\"support\" + 0.010*\"budget\" + 0.010*\"offic\" + 0.009*\"fund\" + 0.007*\"black\"\n",
      "Topic: 3 \n",
      "Words: 0.043*\"polic\" + 0.039*\"hous\" + 0.035*\"depart\" + 0.030*\"resid\" + 0.027*\"budget\" + 0.027*\"fund\" + 0.025*\"communiti\" + 0.020*\"afford\" + 0.018*\"harass\" + 0.017*\"limit\"\n",
      "Topic: 4 \n",
      "Words: 0.009*\"prairi\" + 0.008*\"email\" + 0.006*\"manag\" + 0.006*\"public\" + 0.006*\"land\" + 0.006*\"send\" + 0.006*\"work\" + 0.006*\"dog\" + 0.005*\"time\" + 0.005*\"open\"\n",
      "Topic: 5 \n",
      "Words: 0.010*\"polic\" + 0.009*\"census\" + 0.007*\"state\" + 0.007*\"offic\" + 0.007*\"https\" + 0.005*\"bike\" + 0.005*\"colorado\" + 0.005*\"email\" + 0.004*\"time\" + 0.004*\"come\"\n",
      "Topic: 6 \n",
      "Words: 0.017*\"hous\" + 0.007*\"state\" + 0.007*\"home\" + 0.007*\"communiti\" + 0.007*\"afford\" + 0.005*\"resid\" + 0.005*\"provid\" + 0.005*\"petit\" + 0.005*\"increas\" + 0.005*\"charter\"\n",
      "Topic: 7 \n",
      "Words: 0.007*\"like\" + 0.006*\"time\" + 0.006*\"year\" + 0.006*\"traffic\" + 0.005*\"park\" + 0.005*\"need\" + 0.005*\"street\" + 0.005*\"work\" + 0.005*\"peopl\" + 0.005*\"communiti\"\n",
      "Topic: 8 \n",
      "Words: 0.016*\"peopl\" + 0.013*\"shelter\" + 0.011*\"homeless\" + 0.008*\"communiti\" + 0.007*\"street\" + 0.007*\"need\" + 0.007*\"time\" + 0.007*\"year\" + 0.006*\"servic\" + 0.006*\"librari\"\n",
      "Topic: 9 \n",
      "Words: 0.021*\"homeless\" + 0.018*\"hous\" + 0.017*\"servic\" + 0.013*\"peopl\" + 0.013*\"communiti\" + 0.011*\"includ\" + 0.010*\"fund\" + 0.008*\"recommend\" + 0.008*\"depart\" + 0.008*\"shelter\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = lda_model.top_topics(bow_corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
